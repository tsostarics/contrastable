---
title: "contrasts"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{contrasts}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette describes some of the contrast coding helpers this package provides.
It should be noted that this package does not seek to provide an interface for
creating hypothesis matrices and their respective contrast matrices. For that
functionality you might look into the `multcomp` or `hypr` packages. The contrast
functionality of this package is focused on the following:

- Easily implement commonly used contrast coding schemes
- Make reference levels explicit
- Cut down on repetitive coding involved in setting contrasts
- Retain interpretable labels in model summary coefficients
- Allow the implementation of custom contrasts (but again not their creation)

This vignette will not go into detail how different contrast schemes are derived or
interpreted, but will describe some of the high level differences. I recommend
reading the following:

- [UCLA R Library Contrast Coding Systems for Categorical Variables](https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/)
- [How to capitalize on a priori contrasts in linear (mixed) models: A tutorial](https://www.sciencedirect.com/science/article/pii/S0749596X19300695)
- [Regresion modeling for linguistic data (preprint)](https://osf.io/pnumg/)

There is a very small overview of hypothesis matrices in the second to last
section, but I will not provide a discussion of orthogonality as it relates
to contrasts.

```{r setup, message=FALSE, warning=FALSE}
library(contrastable)
library(dplyr)
library(MASS)
mdl_data <- 
  mtcars |> 
  as_tibble() |> 
  mutate(cyl = factor(cyl), 
         twolevel = round(runif(n()),0),
         twolevel = ifelse(twolevel == 1, "a", "b"),
         twolevel = factor(twolevel),
         gear = factor(gear),
         carb = factor(carb))
```

## Introduction to contrasts

Statistical models such as linear regression need numbers to operate with,
but often we have discrete categories that we want to model such as ethnicity,
country, treatment group, etc.
Typically, we have some comparisons in mind before we do our statistics:
compare the group receiving treatment to a reference level who did not, or
something like compare group A to group B.
**Contrast coding** is the process of assigning numbers that encode the
comparisons we want to make prior to fitting a statistical model.
What this allows us to do is strategically set up our model to be interpretable
in a way that's meaningful to us even though the *fit* of the statistical model
is unchanged.
So, contrast coding is important for inferential statistics and reporting
coefficients correctly, but is not that important for group-level predictions.

Throughout this vignette and package, I refer to different **contrast schemes**,
which I define as *an encoding of a principled set of comparisons for an arbitrary number of factor levels*.
The important bit here is the *arbitrary* number part.

To start with an example, consider an experiment where people are tasked with
keeping track of the location of different shapes under different levels of
cognitive load, such as needing to remember different strings of numbers.
Basically, a change detection task with a digit span cognitive load manipulation.
We'll call the levels of this *cognitive load* factor none, low, and high.
A priori, the speed with which people detect a shape that changes location should
vary depending on the cognitive load.
Specifically, reaction time (RT) should be slower when cognitive load is higher.

What kinds of comparisons could we make, and how do we encode these in our
statistical model?
One comparison might be to compare low to none, then high to none.
Another could be to compare low to none, then high to *low*.
Yet another could be to compare low to none, then high to *low and none* together.
Or, we could compare each level to the average across the conditions.[^dfnote]
Specifying these different comparisons, which will really just amount to differences in
group means, is our goal here.

In our example, what if we went found that our high cognitive load condition
wasn't high enough?
What if we needed to add an extra-high level?
We could add a comparison of extra-high to none, or compare extra-high to high.
Or, we could compare extra-high to none plus low plus high together.
Ideally, if we're going for pairwise comparisons from a reference level,
successive differences between levels, or some kind of nested set of comparisons,
we would want to be able to specify this consistently.

 [^dfnote]: Technically, due to degrees of freedom, we'd compare only 2 of the
 3 levels to the average.


Throughout this vignette and package, I refer to different **contrast schemes**,
which I define as *an encoding of a principled set of comparisons for an arbitrary number of factor levels*.
The important bit here is the *arbitrary* number part such that if the goal
is to take pairwise comparisons from a reference level, then adding a new level
should only amount to encoding an additional pairwise comparison to the same
reference level.
I'll contrast this approach to a more manual approach to contrast coding, where
you would explicitly write out, in code, every single comparison for every
single factor you want to make.
Consider if we added a new three-level predictor crossed with our four level
example from before (we'll call the new predictor *group* with levels A, B, C).
If we also just wanted to do pairwise comparisons, a scheme approach would
encode *pairwise comparisons* for cognitive load and *pairwise comparisons*
for the new factor.
The manual approach would say to encode low-none, high-none, and extra high-none;
then, encode B-A, and C-A.
If we introduce a new group D later, we have to remember to go in and specify 
D-A too.

So, while the manual approach is maximally explicit about exactly what we want
to compare, it's also more things to write out and more chances that we make a
mistake while implementing it.
Given that contrasts are specified using matrices in R, the chances of a mistake
are high.
Accordingly, R provides a few functions that implement common contrast schemes
such as `contr.treatment` and `contr.sum`, which return matrices given a number 
of levels.
However, there's some trickiness with them.
Below is a quick list of some issues this package attempts to circumvent; if
you're familiar with contrast coding from your own work, some of this may sound
familiar and some of it may surprise you.
If you're not sure what I mean by something, hang tight and they'll be explained
more later in the vignette.

 - When setting contrasts to a factor that differ from the R session's default
 contrasts, the labels for the comparisons in the output of the statistical model
 are reset. This requires the researcher to keep track of which numeric indices
 (1, 2, etc.) correspond to which comparisons---which also requires keeping
 track of the alphabetical order of the levels. Alternatively, the researcher
 can set the comparison labels using `dim()`, `dimnames()`, or `colnames()`.
 In my experience, I rarely see people in my field do this, and so I believe it
 would be naive to expect people to suddenly (learn how to and) start doing so.
 - The reference level for the default contrasts, `contr.treatment`, place the
 reference level as the first level alphabetically while `contr.sum` places the
 reference level as the LAST level alphabetically. To verify for yourself, try
 running `contr.treatment(5)` and `contr.sum(5)`. respectively, the reference
 levels are identifiable by the rows containing either all 0s or all -1s.
 - Related to the above, when people want to use $\pm.5$ for their contrasts
 for a two-level factor, it is not uncommon to see something like 
 `-contr.sum(2)/2`. However, this ***does not generalize*** when the number of
 levels is not 2.
 - `contr.helmert` returns unscaled matrices, giving effect estimates that need
 to be manually scaled. Tests of statistical significance are still meaningful,
 but interpreting the magnitude of effects using matrices from this function
 are likely to be incorrect if not scaled manually.
 - Quite a few contrasts simplify to $\pm.5$ when there are two levels. For
 example, helmert coding and backward difference coding both give +.5 and -.5.
 But, if we were to add a third level to these, the values for the newly added
 comparison are NOT the same. Accordingly, if we're not explicit about what the
 **goal** of the comparisons are (nested comparisons vs successive comparisons)
 then future researchers following up on our work might attempt to use the same
 contrast scheme but not understand what the new comparison is.




## Motivation 

The default contrast scheme for factors in R is **treatment coding**, which tests
the difference between each level of a factor and the level set as the reference 
level. Often this doesn't correspond to hypotheses we want to test, so we need to 
change it ourselves.

```{r}
contrasts(mdl_data$twolevel)
contrasts(mdl_data$carb)
```

Typically we would change these manually using `contrasts<-`, for example
this would implement R's built in sum coding for a 6 level factor.

```{r}
contrasts(mdl_data$carb) <- contr.sum(6)
contrasts(mdl_data$carb)
```

Compare this contrast matrix to the treatment coded matrix previously shown
for this factor. There are two things to note here. First, in the treatment
coded matrix the *first row* corresponding to level 1 was all 0, denoting 1 as
the reference level, but here the reference level is actually level 8, which has
all -1s. This may not be what you intended.
Second, the **column names have changed**. The column names represent the labels
for the comparisons we're making with our contrast matrix. In the treatment
coded matrix, the labels are `c(2, 3, 4, 6, 8)`, which would be shown in the
coefficient names in a model summary. In the matrix from `contr.sum(6)`, they're
not the same. Notably, what would correspond to the comparison for level 6 would
be displayed as `carb5` in our model output! We'd like to have meaningful labels
that make it easier to interpret.

Occasionally people will mention that there's a "standard", "tradition", or
"convention" that `coef1` corresponds to something. This isn't really the case,
it's only a "convention" because people are unknowingly erasing or not setting
the labels themselves. There's no reason to need to keep track of what 1 represents
for all your categorical variables in your head, as you'll likely make a mistake.

```{r reset, echo = FALSE}
mdl_data <- 
  mtcars |> 
  as_tibble() |> 
  mutate(cyl = factor(cyl), 
         twolevel = round(runif(n()),0),
         twolevel = ifelse(twolevel == 1, "a", "b"),
         twolevel = factor(twolevel),
         gear = factor(gear),
         carb = factor(carb))
```

## Contrast coding 

The basis for this package is the `use_contrasts()` function, which takes
a factor vector (i.e., a factor column in a dataframe) and a desired contrast 
scheme and returns a new contrast matrix.
The contrast scheme can be passed as either a function that generates contrast
matrices, such as `contr.sum`, or a matrix you've created yourself. In the next
section I will outline additional functionality that allows you to more quickly
set contrasts to your data, but for the time being this section will discuss
what the general output you can get would look like.

Here we use `contr.sum` to get a contrast matrix using the `carb` column.

```{r}
use_contrasts(mdl_data$carb, contr.sum)
```

There are two things to note here. First, the comparison labels have been retained.
This makes model interpretation easier. Second, the reference level has been
set to the first level alphabetically, rather than the last level. This is
the default behavior, inherited from R's normal alphabetical ordering, but can 
be set to whatever you want.

```{r}
use_contrasts(mdl_data$carb, contr.sum, reference_level = 4)
```

Note how the comparison labels have also changed appropriately.

The setting of reference levels only applies to schemes that utilize a reference
level. These include the following functions (R's default functions use a `.` while
this package's functions use `_`s)

- `contr.sum` and `sum_code`: compare each non-reference level to the grand mean
- `contr.treatment` and `treatment_code`: compare each level to the reference level (intercept = mean of reference level)
- `scaled_sum_code`: compare each level to the reference level (intercept = grand mean)

The following schemes depend on a particular order of factors. By default,
R orders levels alphabetically. If this isn't what you want, use `levels<-` to
change the ordering manually *before* applying contrast coding.

- `forward_difference_code`: compare each level k to level k+1 (eg 1-2, 2-3)
- `backward_difference_code`: compare each level k to level k-1 (eg 3-2, 2-1)
- `helmert_code` and `contr.helmert`: compare each level k to the mean of all levels below if (eg <2, <3). 
However, note that `contr.helmert` uses an unscaled contrast matrix, returning values that need to be manually scaled.
The statistical tests are exactly the same as `helmert_code`, but the magnitudes in the mean differences will be lower than they actually are. 
- `reverse_helmert_code`: compare each level k to the mean of all levels above it (eg >1, >2)


Orthogonal polynomial contrasts with `contr.poly`  and `orth_polynomial_code`
are typically used to identify
trends in ordinal predictors. In fact, just as `contr.treatment` is the default
contrast setting for unordered factors in R, `contr.poly` is the default for
ordered factors. You can view the default settings using `options()`, but
in general I do not recommend changing the defaults and relying on them.

```{r}
options('contrasts')
```

Nonetheless, orthogonal polynomial contrasts aren't used for group comparisons,
rather looking for polynomial trends across ordered scores assigned to each level,
so the "comparison" labels are different. But this isn't
an issue, and will still work as expected.

```{r}
use_contrasts(mdl_data$carb, contr.poly)
```

## Setting contrasts en masse

This section will outline the main functionality of this package: setting
multiple contrast schemes quickly. This can be done by either creating a list
of contrasts to give to the `contrasts` argument in model-fitting functions or
by setting them directly to the dataframe.

### Utilizing `contrasts` argument in model functions

Rather than manually setting the contrasts on the data frame itself, you can
use the contrasts argument in functions like `lm`, which take a named
list of contrast matrices where the names correspond to factor predictors. This
package provides a function `enlist_contrasts` to take advantage of this. Make
sure your model fitting function supports this argument, as `brm` does not use this
(see the next section).

```{r}
my_contrasts <- 
  enlist_contrasts(mdl_data,
                   cyl ~ contr.sum + 6, # Set the reference level with + ___
                   twolevel ~ scaled_sum_code + "a",
                   gear ~ forward_difference_code,
                   carb ~ helmert_code)

my_model <- lm(mpg ~ cyl + twolevel + gear + carb, 
               data = mdl_data,  
               contrasts = my_contrasts)

summary(my_model)
```

The left hand side of each formula in `enlist_contrasts` should be the unquoted
name of a factor column, and the right hand side should be of the following:

- An unquoted function name that generates contrast matrices
- ***OR*** An unquoted variable name that's assigned to a contrast matrix
- ***OR*** A `matrix()` call, which will be captured and evaluated
- ***AND*** An optional reference level when applicable, following a `+`. String
names should be quoted, if the label happens to be numeric you can leave the number
unquoted. You can also use an unquoted variable name that contains the reference
level.
- ***AND*** An optional specification for which level to use as the intercept following
a `*`. Same
syntax as the reference level, see section titled "Changing Underlying Intercept"
- ***AND*** If you use polynomial contrasts, an optional sequence (integer vector)
of which trends you would like to drop following a `-`. Typically of the form 
`- a:b` where a and b are integers (eg `- 3:5` to drop cubic through 5th power
trends)
0 ***AND*** an optional vector of labels to use for the comparisons following
a `|`, which must be the last operator on the RHS if used. 

When using this method you should set contrasts for all factors. You'll receive
a message if you don't set one or more, along with what the default contrasts
are as specified by `options('contrasts')` for both ordered and unordered factors.
While not shown in this vignette, these are also color coded (blue for unordered,
red for ordered) in the console.

```{r}
contrast_list <- enlist_contrasts(mdl_data, carb ~ helmert_code)
```

### Setting multiple contrasts on dataframe

As previously mentioned, the `brm` function from the `brms` package (used to
fit bayesian models) does not have a `contrasts` argument. This means we need
to set the contrasts on the dataframe itself. But, this doesn't mean we need
to revert to multiple `contrasts<-` lines. We can use `set_contrasts`, which
uses the same syntax as `enlist_contrasts` but returns a new copy of the dataframe
where the contrast schemes are applied accordingly. The usual warnings and
messages still apply.

```{r}
mdl_data2 <- 
  set_contrasts(mdl_data,
                cyl ~ contr.sum + 6,
                twolevel ~ scaled_sum_code + "a",
                gear ~ forward_difference_code,
                carb ~ helmert_code)

# Compare treatment coding to helmert coding (note these are different dfs)
contrasts(mdl_data$carb)
contrasts(mdl_data2$carb) |> fractions()
```

One other thing to know is that when calling `get_prior` or setting priors for
coefficients in general, `brms` actually changes the names slightly when prepping
the model for running in stan. For example, using backward difference coding gives
coefficient names like `2-1`, but this gets changed to `2M1`. If you're doing
programmatic setting of priors, it's something to keep in mind. You can also
use `|` to set the names to something yourself.

## Note about 2 level factors

Coding factors with only 2 levels is a bit tricky conceptually because there
is only one possible comparison you can make: level A to level B. Thus, many of 
the different coding schemes end up being mathematically equivalent.

```{r}
helmert_code(2) # Compare k to >k
scaled_sum_code(2) # Compare k to reference level
forward_difference_code(2) # Compare k to k+1
```

In many introductions to contrast coding, the motivation for using `+/-.5` is
something like this:

- `0, 1` from `contr.treatment(2)` puts the intercept at the reference level, 
which we don't always want
- `-1, 1` from `-contr.sum(2)` keeps the same reference level and the intercept 
is now the grand mean, but this tests half the difference between levels (i.e.,
the distance between a level and the intercept)
- `-.5, .5` from `-contr.sum(2)/2` scales the estimate so it tests the full 
difference between levels.

All of this is true, but it leads to an issue when naively extending this line
of thinking beyond 2 levels. That is, one might be tempted to use the following
matrix for "sum coding a 4 level factor"

```{r}
-contr.sum(4)/2
```

Yet, this contrast matrix ***does not*** test the hypotheses that $\mu_1=\mu_4$
and $\mu_2=\mu_4$ and $\mu_3=\mu_1$ in the same way that the 2 level matrix tested
$\mu_1=\mu_2$. Rather, it tests the hypothesis that 
$1.5\mu_1 =.5\mu_2+.5\mu_3 + .5\mu_4$ etc. To actually compare, and test the 
difference between, each level and the reference level, you need to use the 
following matrix, which this package provides a helper for:

```{r}
scaled_sum_code(4) |> MASS::fractions()
```

We can verify this by looking at the hypothesis matrices.

```{r}
# Not what we want
matrix(c(1,1,1,1,-contr.sum(4)/2), nrow = 4) |>
  t() |> solve() |> fractions()

# Actually what we want
matrix(c(1,1,1,1,scaled_sum_code(4)), nrow = 4) |>
  t() |> solve() |> fractions()
```

Rather than thinking about "testing half the difference," framing things in terms
of the underlying hypothesis matrix being tested is more generalizable. Assume
level 1 is `A` (and is the reference level) and level 2 is `B` in these
descriptions:

- `0, 1` from `contr.treatment(2)` puts the intercept at the reference level
and tests the difference $\mu_B-\mu_A$. Each comparison tests a distance from
the reference level. We use the term *treatment coding*.
- `-1, 1` from `-contr.sum(2)` puts the intercept at the grand mean 
($GM=\frac{\mu_A+\mu_B}{2}$) and tests the difference $\mu_B - GM$. Each comparison
tests a distance from the grand mean. We use the term *sum coding*
- `-.5, .5` from `-contr.sum(2)/2` puts the intercept at the grand mean and 
tests the difference $\mu_B - \mu_A$. Each comparison tests a distance from
the reference level. We use the term *scaled sum coding*.

It's worth noting that the terms "sum coding" and "scaled sum coding" are
***not*** consistent across disciplines. Other terms that are used are simple
coding, deviation coding, effects coding, sum to zero coding, and contrast coding. When
referring specifically to coding factors with 2 levels, sometimes just the numbers
are used as in 0/1 coding, -1/1 coding, -.5/+.5 coding. I recommend that you
choose a term from your discipline and stick to it, but also provide the exact
contrast or hypothesis matrices in an appendix, preregistration, or
supplementary material.

## Changing Underlying Intercept

I know I said I wouldn't give a discussion on how contrasts are derived, but 
there's one additional functionality that kind of necessitates
describing the process a little. We know that contrast matrices have $k$ rows
and $k-1$ columns for our $k-1$ comparisons (derived from $k-1$ degrees of
freedom). But models also give an intercept term: where does that come from?
Moreover, why is it conveniently the grand mean for basically everything but
treatment coding? What if I wanted a particular coding scheme for my level
comparisons, but the intercept representing the mean of my highest level rather
than the grand mean (which might not be meaningful)? Is this possible?

First, recall that scaled sum coding puts the intercept at the grand mean and
the comparisons are between the reference level and the level being compared.

```{r}
fractions(scaled_sum_code(4))
```

The intercept in this case is actually represented by an omitted column of 1s

```{r}
matrix(c(rep(1,4),
         scaled_sum_code(4)),
       nrow = 4) |> fractions()
```

Why are there fractions though? If I'm comparing level 1 to level 2, why aren't
the others 0? Why aren't they just 0 compared to 1, like in treatment coding? This
intuition is actually valid; not at the level of the contrasts but at the level
of the hypotheses you want to test. Turns out those hypotheses actually underlie
this matrix, and linear algebra transformations can be used to go between the two.
For more details, see the paper on capitalizing on a priori contrasts. For now
just know that we can take the inverse of the transpose of a matrix to go between
the two (sometimes the transpose is omitted depending on the author, which means
you'd go back and forth between interpreting columns or rows as comparisons).

```{r}
contrast_matrix <- 
  matrix(c(rep(1,4),
           scaled_sum_code(4)),
         nrow = 4)

hypothesis_matrix <- solve(t(contrast_matrix))

fractions(hypothesis_matrix)
```

This gives us our hypothesis matrix, and we can tell from the first column that
the intercept is the grand mean because each level contributes to a single value.
That is, the sum of the means of our 4 levels, divided by 4, is the grand mean;
hence the weight of each mean is 1/4. Our comparisons show that we're comparing
the fourth level (all -1s) to the 1st, 2nd, and 3rd levels for our three 
comparisons. This is maybe more transparent than the 3/4 and -1/4s in the contrast
matrix.

However, consider if we didn't want the grand mean. What if we wanted the
intercept to be a particular level's mean, say our reference level of 4? Rather
than having each level contribute to the intercept, we just want 1. So we can use
this matrix:

```{r}
hypothesis_matrix2 <- hypothesis_matrix
hypothesis_matrix2[,1] <- c(0,0,0,1)
hypothesis_matrix2
```

Think critically here: Our intercept is now the mean of level 4, the other levels
don't contribute to it. Each comparison is now the difference between a level and
the reference level. If that's the case, we should have just recreated treatment
coding! But we need to convert from our hypothesis matrix to the contrast matrix.
Remind yourself what the contrast matrix from treatment coding should look 
like before proceeding (hint: lots of 0s and 1s).

```{r}
# Inverse of the transpose, remove the first column to get contrasts
maybe_treatment_contrasts <- solve(t(hypothesis_matrix2))[,2:4]

# I'm manually reordering to make the reference level the 4th level here
definitely_treatment_contrasts <- unname(contr.treatment(4)[c(2,3,4,1),])

maybe_treatment_contrasts
definitely_treatment_contrasts

# Moment of truth: Are they the same?!
all(maybe_treatment_contrasts == definitely_treatment_contrasts)
```

And indeed we recreated treatment coding by changing the underlying hypothesis
matrix. That was so much work to get something already available. Consider
a harder case of forward difference coding with the intercept changed.

```{r}
forward_contrasts <- forward_difference_code(6)
forward_hypotheses <- 
  matrix(c(rep(1,6), forward_contrasts), nrow = 6) |> t() |> solve()

fractions(forward_contrasts)
fractions(forward_hypotheses)
```

Now we'll change the intercept to level 6.

```{r}
new_forward_hypotheses <- forward_hypotheses
new_forward_hypotheses[,1] <- c(0,0,0,0,0,1)
new_forward_hypotheses

new_forward_contrasts <- solve(t(new_forward_hypotheses))[,2:6]
new_forward_contrasts
```

The matrix changed pretty substantially compared to before, even though all
we changed was the intercept. This still required quite a few steps to just
change the level we want to be the intercept. Thankfully `enlist_contrasts`
and related functions `set_contrasts`, `use_contrasts`, and `use_contrast_function`
have an argument to change this more simply. 

The syntax for `enlist_contrasts` and `set_contrasts` requires putting a `*`
before the name of the level you want to use. If you're using a reference level,
you can also specify that with `+` as usual. You can also use both, but specifying
a reference level is only applicable to schemes where that's meaningful, like
in `contr.treatment`, `contr.sum`, and `scaled_sum_code`. Recall from our earlier
derivation that scaled sum coding with the intercept specified as the reference
level is equivalent to treatment coding, which should be evident here.

```{r}
enlist_contrasts(mdl_data, 
                 carb ~ forward_difference_code * 8,
                 gear ~ scaled_sum_code + 4 * 4)
```

Using the singular `use_contrast` just requires specifying the `reference_level`
and `set_intercept` arguments as needed.

```{r}
use_contrasts(mdl_data$gear, 
              scaled_sum_code, 
              reference_level = 4, 
              set_intercept = 4)
```

This functionality should only be used when you're using a function to generate
contrasts. Currently, I don't allow for multiple levels to be used as the intercept
(e.g., only 2 of 4 levels). If you really think you need to do that, you probably
have a good handle on contrasts and hypothesis matrices, so you should specify
the matrix manually yourself and use that as an argument. If you think you need
to do that but you *don't* have a good handle on contrasts and hypothesis matrices,
you should go back and read the paper cited at the top of this vignette again.
Remember that when setting matrices yourself, you should specify the row names
to be your factor levels and your column names to be informative comparison 
labels.

## Dropping trends from polynomials

When using polynomial contrasts you can drop higher level trends for the sake
of parsimony. However, even when using
orthogonal polynomials, your estimates for each trend can differ depending on
whether higher trends are included. If you do want to remove higher level trends
though, you can use the `-` operator in the contrast formula. Let's use the
`diamonds` data set as an example.

```{r}
library(ggplot2,diamonds) # load just the diamonds dataset

# Clarity has 8 levels, so we'll remove anything higher than the cubic trend
my_contrasts <- enlist_contrasts(diamonds,
                                 clarity ~ contr.poly - 4:7)

# Higher trends removed
lm(price ~ clarity, data = diamonds, contrasts = my_contrasts) |> 
  broom::tidy()

# Higher trends retained
lm(price ~ clarity, data = diamonds) |> 
  broom::tidy()

# Trying to manually remove trends on the contrast in the data set doesn't work
diamonds1 <- diamonds
contrasts(diamonds1$clarity) <- contr.poly(8)[,1:3]
lm(price ~ clarity, data = diamonds1) |> 
  broom::tidy()

# Decomposing the contrasts to create new columns for the first three trends
# also works well
diamonds2 <- decompose_contrasts(diamonds, ~ clarity)
lm(price ~ clarity.L + clarity.Q, data = diamonds2) |> 
  broom::tidy()
```

Note how when we tried to remove the trends on the factor column 
`diamonds1$clarity` it doesn't work *and* it messes up the labels for the terms.
This also means that you cannot drop trends with `set_contrasts`, and it will
throw a warning that it will ignore that argument when it's used:

```{r}
# Just show the messages, not the output
invisible(set_contrasts(diamonds, clarity ~ contr.poly - 4:7))
```

# Glimpse Contrasts

This is some newer functionality to gain some quick insight into the factors used
in your dataset. It uses the same syntax as `enlist_contrasts` and `set_contrasts`
and provides a dataframe with some useful information. Note however that
`glimpse_contrasts` doesn't change the dataframe itself, so you'll usually need
to pair this with a call to `set_contrasts`. Note the warning here.

```{r}
tstdf <- mtcars
tstdf$cyl <- factor(tstdf$cyl)
contrast_info <- glimpse_contrasts(tstdf, 
                                   vs ~ contr.treatment,
                                   am ~ scaled_sum_code + 1,
                                   gear ~ helmert_code,
                                   carb ~ contr.poly,
                                   show_all_factors = TRUE)

contrast_info
```

In this table we can easily reference what contrast scheme we used, what its
reference level is when applicable, and how it may affect the interpretation
of the intercept. Here, the intercept is to be interpreted as the average unit
(whatever that is for your model) at level `0` of `vs` and level `4` of `cyl`,
while it's marginalized across the other predictors. Note that while helmert
and reverse helmert schemes don't have a reference level per se, the reference
level shown in the table helps to show what the starting point is in case you
forget which direction it's going. Here, the levels are `3, 4, 5` and comparisons
start at `5`, which means they'll be going down: `4-5` then `3-(4,5)`.

We can also see if any are orthogonal or not and whether we
explicitly set them or if R used the system defaults. Note that you shouldn't
call `glimpse_contrasts` on a dataframe you've already constructed with
`set_contrasts`. You might think that using this would require you to copy
and paste all the formulas twice, once to `enlist/set_contrasts` and again
to `glimpse_contrasts`, but you can invoke `enlist_contrasts` from `glimpse_contrasts`
using the `return.list` argument if you want to do it in one go. Doing so
will return a list where the first item is the glimpse dataframe and the
second is the list of named contrast matrices that can be passed to a model
fitting function.

```{r}
contrast_info <- glimpse_contrasts(tstdf, 
                                   vs ~ contr.treatment,
                                   am ~ scaled_sum_code + 1,
                                   gear ~ helmert_code,
                                   carb ~ contr.poly,
                                   show_all_factors = TRUE,
                                   return_list = TRUE)

my_contrasts <- contrast_info$contrasts
contrast_glimpse <- contrast_info$glimpse
```

Alternatively, you can specify the contrast formulas in a list and save
that to a variable, then pass that around to the different functions.

```{r}
schemes <- list(vs ~ contr.treatment,
                am ~ scaled_sum_code + 1,
                gear ~ helmert_code,
                carb ~ contr.poly)

contrast_glimpse <- glimpse_contrasts(tstdf, schemes)
contrast_glimpse # Review if needed
tstdf <- set_contrasts(tstdf, schemes, verbose = FALSE)
```


We can also explicitly add the namespace for the function we used.

```{r}
contrast_info <- glimpse_contrasts(tstdf, schemes, add_namespace = TRUE)
contrast_info
```

# Setting comparison names manually

This functionality has been mentioned before in this vignette but this 
section will focus on it explicitly. 

Consider a factor with the following levels: s, sh, n, t. With four levels there 
are of course three degrees of freedom for three comparisons. One comparison that 
could be made is comparing each level with the plosive t using the following matrix:

```{r}
phone_df <- data.frame(phone = factor(c('S', 'SH','N', 'T'),
                                      levels = c('S', 'SH','N', 'T')))

enlist_contrasts(phone_df, 
                 phone ~ scaled_sum_code + "T")
```

The column names automatically created here make sense for these and are easy to 
interpret in model summary coefficients of the form `phoneN`, `phoneS`, `phoneSH` 
However, another option would be to use helmert coding, yielding this matrix:

```{r}
enlist_contrasts(phone_df, 
                 phone ~ helmert_code)
```

This scheme tests the difference between s vs sh (Compact vs Diffuse sibilants),
then between s & sh vs n (Sibilants vs Nasals), then s & sh & n vs t (Alveolar
Continuants vs Stops, or non-stops vs stops). However, the labels aren't
entirely transparent for those comparisons and are read literally as "values
less than sh", "values less than n" when this variable isn't technically ordinal
in nature. It would be more useful easier to interpret if we set more
informative labels to get coefficients like `phoneCompactvsDiffuse`,
`phoneSibvsNas`, `phoneStopvsCont`. We can do this with using `set_contrasts` and 
its related functions using the `|` operator when setting contrast schemes.

```{r}
# Note you can add a line break after (or before, really) the | for readability
enlist_contrasts(phone_df, 
                 phone ~ helmert_code | 
                   c("CompactvsDiffuse","SibvsNas", "StopvsCont"))
```

One thing to note is that some model fitting functions will shorten parameter
names in certain settings. For example, if you use `lmer` and do something like
this:

```{r, eval=FALSE}
# Not run to avoid loading lme4
library(lme4)
library(contrastable)
mdl_data <- set_contrasts(mtcars, cyl ~ sum_code |
                            c("longlonglonglonglongname",'shortname'))
lmer(mpg ~ cyl + (1|gear), data = mdl_data) |> summary()
```

While not run here, the output of the fixed effects table in the summary
will show the full names of the parameters. In the variance-covariance matrix,
the row names get shortened to `cyllnglngln` and `cylshortnam`. The column
names become `(Intr)` and `cyllng`.

# Conclusion

Hopefully this vignette highlighted some useful functionality available in this
package. It does presuppose that you know a bit about what each scheme does. But,
looking at the documentation for each function provides a bit of help about
how to interpret fixed effects, eg `?scaled_sum_code`. The interpretation
of interaction terms is more complicated and beyond the scope of this vignette,
so choose your contrasts and models wisely!
